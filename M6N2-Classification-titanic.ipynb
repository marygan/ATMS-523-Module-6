{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See LICENSE for N1 and N2 for software license for this notebook.\n",
    "\n",
    "## Classification\n",
    "\n",
    "In this lecture, I will bring together various techniques for feature engineering that we have covered in this course to tackle a classification problem. This would give you an idea of the end-to-end pipeline to build machine learning algorithms for classification. \n",
    "\n",
    "I will:\n",
    "- build a gradient boosted tree\n",
    "- use feature-engine for the feature engineering steps\n",
    "- set up an entire engineering and prediction pipeline using a Scikit-learn Pipeline\n",
    "\n",
    "============================================================================\n",
    "\n",
    "## In this demo:\n",
    "\n",
    "We will use the titanic dataset, please refer to lecture **Datasets** in Section 1 of the course for instructions on how to download and prepare this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# for feature engineering\n",
    "from feature_engine import imputation as mdi\n",
    "from feature_engine import discretisation as dsc\n",
    "from feature_engine import encoding as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "\n",
    "cols = [\n",
    "    'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'cabin',\n",
    "    'embarked', 'survived'\n",
    "]\n",
    "\n",
    "data = pd.read_csv('./data/titanic.csv', usecols=cols)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of variables (section 2)\n",
    "\n",
    "Let's find out what types of variables there are in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's inspect the type of variables in pandas\n",
    "\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are categorical and numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's inspect the variable values\n",
    "\n",
    "for var in data.columns:\n",
    "    print(var, data[var].unique()[0:20], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There continuous and discrete variables and also mixed variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list of variables  types\n",
    "\n",
    "# numerical: discrete vs continuous\n",
    "discrete = [var for var in data.columns if data[var].dtype!='O' and var!='survived' and data[var].nunique()<10]\n",
    "continuous = [var for var in data.columns if data[var].dtype!='O' and var!='survived' and var not in discrete]\n",
    "\n",
    "# mixed\n",
    "mixed = ['cabin']\n",
    "\n",
    "# categorical\n",
    "categorical = [var for var in data.columns if data[var].dtype=='O' and var not in mixed]\n",
    "\n",
    "print('There are {} discrete variables'.format(len(discrete)))\n",
    "print('There are {} continuous variables'.format(len(continuous)))\n",
    "print('There are {} categorical variables'.format(len(categorical)))\n",
    "print('There are {} mixed variables'.format(len(mixed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable characteristics (section 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing data\n",
    "\n",
    "data.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is missing data in our variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cardinality (number of different categories)\n",
    "\n",
    "data[categorical+mixed].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some variables are highly cardinal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers\n",
    "\n",
    "data[continuous].boxplot(figsize=(10,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers in discrete\n",
    "data[discrete].boxplot(figsize=(10,4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some variables show outliers or unusual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values bigger than 3 are rare for parch\n",
    "\n",
    "data['parch'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature magnitude\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features are in different ranges or scales. But this is not relevant for gradient boosted trees. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineering mixed type of variables (section 11)\n",
    "\n",
    "Extract numerical and categorical parts of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cabin\n",
    "data['cabin_num'] = data['cabin'].str.extract('(\\d+)') # captures numerical part\n",
    "data['cabin_num'] = data['cabin_num'].astype('float')\n",
    "data['cabin_cat'] = data['cabin'].str[0] # captures the first letter\n",
    "\n",
    "# show dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we extracted the numerical and categorical part, we can discard the mixed variable Cabin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop original mixed\n",
    "\n",
    "data.drop(['cabin'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate into training and testing set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('survived', axis=1),  # predictors\n",
    "    data['survived'],  # target\n",
    "    test_size=0.1,  # percentage of obs in test set\n",
    "    random_state=0)  # seed to ensure reproducibility\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data imputation (Section 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical\n",
    "\n",
    "X_train.select_dtypes(exclude='O').isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical\n",
    "\n",
    "X_train.select_dtypes(include='O').isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputation methods I will perform:\n",
    "\n",
    "- Numerical: arbitrary value imputation\n",
    "- Categorical: add missing label imputation\n",
    "\n",
    "Because I will build a Gradient Boosted tree, I am not particularly worried about disturbing linearity or distributions of variables.\n",
    "\n",
    "### Categorical encoding and rare labels (Section 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check cardinality again\n",
    "\n",
    "X_train[['cabin_cat', 'sex', 'embarked']].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I extracted the numerical and categorical part from cabin, its cardinality is not so high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check variable frequency\n",
    "\n",
    "var = 'cabin_cat'\n",
    "(X_train[var].value_counts() / len(X_train)).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categories T and G appear only in few observations, so I will replace them into rare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretisation or Variable transformation (Sections 7 and 8)\n",
    "\n",
    "Let's inspect the variable distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical\n",
    "\n",
    "X_train.select_dtypes(exclude='O').hist(bins=30, figsize=(8,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For decision trees, the variable distribution is not so important, so in principle, we don't need to change it. Also decision trees are robust to outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_pipe = Pipeline([\n",
    "\n",
    "    # missing data imputation - section 4\n",
    "    ('imputer_num',\n",
    "     mdi.ArbitraryNumberImputer(arbitrary_number=-1,\n",
    "                                variables=['age', 'fare', 'cabin_num'])),\n",
    "    ('imputer_cat',\n",
    "     mdi.CategoricalImputer(variables=['embarked', 'cabin_cat'])),\n",
    "\n",
    "    # categorical encoding - section 6\n",
    "    ('encoder_rare_label',\n",
    "     ce.RareLabelEncoder(tol=0.01,\n",
    "                                    n_categories=6,\n",
    "                                    variables=['cabin_cat'])),\n",
    "    ('categorical_encoder',\n",
    "     ce.OrdinalEncoder(encoding_method='ordered',\n",
    "                                  variables=['cabin_cat', 'sex', 'embarked'])),\n",
    "\n",
    "    # Gradient Boosted machine\n",
    "    ('gbm', GradientBoostingClassifier(random_state=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's fit the pipeline and make predictions\n",
    "titanic_pipe.fit(X_train, y_train)\n",
    "\n",
    "X_train_preds = titanic_pipe.predict_proba(X_train)[:,1]\n",
    "X_test_preds = titanic_pipe.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a peek into the prediction values\n",
    "X_train_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train set')\n",
    "print('GBM roc-auc: {}'.format(roc_auc_score(y_train, X_train_preds)))\n",
    "\n",
    "print('Test set')\n",
    "print('GBM roc-auc: {}'.format(roc_auc_score(y_test, X_test_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's explore the importance of the features\n",
    "\n",
    "importance = pd.Series(titanic_pipe.named_steps['gbm'].feature_importances_)\n",
    "importance.index = data.drop('survived', axis=1).columns\n",
    "importance.sort_values(inplace=True, ascending=False)\n",
    "importance.plot.bar(figsize=(12,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "583px",
    "left": "0px",
    "right": "1324px",
    "top": "107px",
    "width": "326px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
