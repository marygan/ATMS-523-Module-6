{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "In this lecture, I will bring together various techniques for feature engineering that we have covered in this course to tackle a regression problem. This would give you an idea of the end-to-end pipeline to build machine learning algorithms for regression.\n",
    "\n",
    "I will:\n",
    "- build a lasso\n",
    "- use feature-engine for the feature engineering steps\n",
    "- set up an entire engineering and prediction pipeline using a Scikit-learn Pipeline\n",
    "\n",
    "===================================================================================================\n",
    "\n",
    "## In this demo:\n",
    "\n",
    "We will use the House Prices dataset, please refer to lecture **Datasets** in Section 1 of the course for instructions on how to download the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## House Prices dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# for feature engineering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from feature_engine import imputation as mdi\n",
    "from feature_engine import discretisation as dsc\n",
    "from feature_engine import encoding as ce\n",
    "\n",
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data = pd.read_csv('./data/houseprice.csv')\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of variables (section 2)\n",
    "\n",
    "Let's go ahead and find out what types of variables there are in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's inspect the type of variables in pandas\n",
    "\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a mixture of categorical and numerical variables. Numerical are those of type **int** and **float** and categorical those of type **object**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have an Id variable, that we should not use for predictions:\n",
    "\n",
    "print('Number of House Id labels: ', len(data.Id.unique()))\n",
    "print('Number of Houses in the Dataset: ', len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Id is a unique identifier for each of the houses. Thus this is not a variable that we can use.\n",
    "\n",
    "#### Find categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find categorical variables\n",
    "\n",
    "categorical = [var for var in data.columns if data[var].dtype=='O']\n",
    "\n",
    "print('There are {} categorical variables'.format(len(categorical)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[categorical].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find temporal variables\n",
    "\n",
    "There are a few variables in the dataset that are temporal. They indicate the year in which something happened. We shouldn't use these variables straightaway for model building. We should instead transform them to capture some sort of time information. Let's inspect these temporal variables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of the numerical variables first\n",
    "numerical = [var for var in data.columns if data[var].dtype!='O']\n",
    "\n",
    "# list of variables that contain year information\n",
    "year_vars = [var for var in numerical if 'Yr' in var or 'Year' in var]\n",
    "\n",
    "year_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[year_vars].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that these variables correspond to the years in which the houses were built or remodeled or a garage was built, or the house was indeed sold. It would be better if we captured the time elapsed between the time the house was built and the time the house was sold for example. We are going to do that in the feature engineering section later in the notebook. \n",
    "\n",
    "We have another temporal variable: MoSold, which indicates the month in which the house was sold. Let's inspect if the house price varies with the time of the year in which it is sold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot median house price per month in which it was sold\n",
    "\n",
    "data.groupby('MoSold')['SalePrice'].median().plot()\n",
    "plt.title('House price variation along the year')\n",
    "plt.ylabel('median House price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The price seems to vary depending on the month in which the house is sold.\n",
    "\n",
    "#### Find discrete variables\n",
    "\n",
    "To identify discrete variables, I will select from all the numerical ones, those that contain a finite and small number of distinct values. See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's visualise the values of the discrete variables\n",
    "discrete = []\n",
    "\n",
    "for var in numerical:\n",
    "    if len(data[var].unique()) < 20 and var not in year_vars:\n",
    "        print(var, ' values: ', data[var].unique())\n",
    "        discrete.append(var)\n",
    "print()\n",
    "print('There are {} discrete variables'.format(len(discrete)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find continuous variables\n",
    "# let's remember to skip the Id variable and the target variable SalePrice\n",
    "# which are both also numerical\n",
    "\n",
    "numerical = [var for var in numerical if var not in discrete and var not in [\n",
    "    'Id', 'SalePrice'] and var not in year_vars]\n",
    "\n",
    "print('There are {} numerical and continuous variables'.format(len(numerical)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect!! Now we have inspected and have a view of the different types of variables that we have in the house price dataset. Let's move on to understand the types of problems that these variables have.\n",
    "\n",
    "### Types of problems within the variables (section 3)\n",
    "\n",
    "#### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's output variables with NA and the percentage of NA\n",
    "\n",
    "for var in data.columns:\n",
    "    if data[var].isnull().sum() > 0:\n",
    "        print(var, data[var].isnull().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers and distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's make boxplots to visualise outliers in the continuous variables \n",
    "# and histograms to get an idea of the distribution\n",
    "\n",
    "for var in numerical:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    fig = data.boxplot(column=var)\n",
    "    fig.set_title('')\n",
    "    fig.set_ylabel(var)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    fig = data[var].hist(bins=20)\n",
    "    fig.set_ylabel('Number of houses')\n",
    "    fig.set_xlabel(var)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of the continuous variables seem to contain outliers. In addition, the majority of the variables are not normally distributed. As we are planning to build linear regression, we need to tackle these to improve the model performance. To tackle the 2 aspects together, I will do discretisation. I will follow discretisation with encoding of the intervals following the target mean, as we do in the **Discretisation plus encoding lecture** in section 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers in discrete variables\n",
    "\n",
    "Now, let's identify outliers in the discrete variables. I will call outliers those values that are present in less than 5 % of the houses. This is exactly the same as finding rare labels in categorical variables. **Discrete variables can be pre-processed / engineered as if they were categorical**. Keep this in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlies in discrete variables\n",
    "\n",
    "for var in discrete:\n",
    "    (data.groupby(var)[var].count() / np.float(len(data))).plot.bar()\n",
    "    plt.ylabel('Percentage of observations per label')\n",
    "    plt.title(var)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the discrete variables show values that are shared by a tiny proportion of houses in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monotonicity between discrete variables and target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's plot the median sale price per value of the discrete\n",
    "# variable\n",
    "\n",
    "for var in discrete:\n",
    "    data.groupby(var)['SalePrice'].median().plot()\n",
    "    plt.ylabel('Median house Price per label')\n",
    "    plt.title(var)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the discrete variables show some sort of monotonic relationship and some don't.\n",
    "\n",
    "#### Number of labels: cardinality\n",
    "\n",
    "Let's go ahead now and examine the cardinality of our categorical variables. That is, the number of different labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot number of categories per categorical variable\n",
    "\n",
    "data[categorical].nunique().plot.bar(figsize=(10,6))\n",
    "plt.title('CARDINALITY: Number of categories in categorical variables')\n",
    "plt.xlabel('Categorical variables')\n",
    "plt.ylabel('Number of different categories')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the variables, contain only a few labels. Then, we do not have to deal with high cardinality. That is good news!\n",
    "\n",
    "Very likely though, they contain rare labels. Why don't you go ahead and plot the frequency of the categories for each categorical variable? We learned how to do this in section 3 of the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's separate into train and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(['Id', 'SalePrice'], axis=1),\n",
    "                                                    data['SalePrice'],\n",
    "                                                    test_size=0.1,\n",
    "                                                    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we will move on and engineer the features of this dataset. The most important part for this course.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal variables (Section 12)\n",
    "\n",
    "First, we will create those temporal variables we discussed a few cells ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate elapsed time\n",
    "\n",
    "def elapsed_years(df, var):\n",
    "    # capture difference between year variable and\n",
    "    # year the house was sold\n",
    "    \n",
    "    df[var] = df['YrSold'] - df[var]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in ['YearBuilt', 'YearRemodAdd', 'GarageYrBlt']:\n",
    "    X_train = elapsed_years(X_train, var)\n",
    "    X_test = elapsed_years(X_test, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[['YearBuilt', 'YearRemodAdd', 'GarageYrBlt']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of the \"year\", now we have the amount of **years that passed** since the house was built or remodeled and the house was sold. Next, we drop the YrSold variable from the datasets, because we already extracted its value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop YrSold\n",
    "X_train.drop('YrSold', axis=1, inplace=True)\n",
    "X_test.drop('YrSold', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture the column names for use later in the notebook\n",
    "final_columns = X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data imputation (section 4)\n",
    "#### Continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print variables with missing data\n",
    "# keep in mind that now that we created those new temporal variables, we\n",
    "# are going to treat them as numerical and continuous:\n",
    "\n",
    "# remove YrSold from the variable list\n",
    "# because it is no longer in our dataset\n",
    "year_vars.remove('YrSold')\n",
    "\n",
    "# examine percentage of missing values\n",
    "for col in numerical+year_vars:\n",
    "    if X_train[col].isnull().mean() > 0:\n",
    "        print(col, X_train[col].isnull().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputation technique to use: **additional variable with NA + median imputation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print variables with missing data\n",
    "\n",
    "for col in categorical:\n",
    "    if X_train[col].isnull().mean() > 0:\n",
    "        print(col, X_train[col].isnull().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputation technique to use: **Add missing label to categorical variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will treat discrete variables as if they were categorical\n",
    "# to treat discrete as categorical using Feature-engine\n",
    "# we need to re-cast them as object\n",
    "\n",
    "X_train[discrete] = X_train[discrete].astype('O')\n",
    "X_test[discrete] = X_test[discrete].astype('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_pipe = Pipeline([\n",
    "\n",
    "    # missing data imputation - section 4\n",
    "    ('missing_ind', mdi.AddMissingIndicator(\n",
    "        variables=['LotFrontage', 'MasVnrArea',  'GarageYrBlt'])),\n",
    "    \n",
    "    ('imputer_num', mdi.MeanMedianImputer(imputation_method='median',\n",
    "                                          variables=['LotFrontage', 'MasVnrArea',  'GarageYrBlt'])),\n",
    "    \n",
    "    ('imputer_cat', mdi.CategoricalImputer(variables=categorical)),\n",
    "\n",
    "    # categorical encoding - section 6\n",
    "    ('rare_label_enc', ce.RareLabelEncoder(\n",
    "        tol=0.05, n_categories=6, variables=categorical+discrete)),\n",
    "    \n",
    "    ('categorical_enc', ce.OrdinalEncoder(\n",
    "        encoding_method='ordered', variables=categorical+discrete)),\n",
    "\n",
    "    # discretisation + encoding - section 8\n",
    "    ('discretisation', dsc.EqualFrequencyDiscretiser(\n",
    "        q=5, return_object=True, variables=numerical)),\n",
    "    \n",
    "    ('encoding', ce.OrdinalEncoder(\n",
    "        encoding_method='ordered', variables=numerical)),\n",
    "\n",
    "    # feature Scaling - section 10\n",
    "    ('scaler', StandardScaler()),\n",
    "    \n",
    "    # regression\n",
    "    ('lasso', Lasso(random_state=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's fit the pipeline\n",
    "house_pipe.fit(X_train, y_train)\n",
    "\n",
    "# let's get the predictions\n",
    "X_train_preds = house_pipe.predict(X_train)\n",
    "X_test_preds = house_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a peek into the prediction values\n",
    "X_train_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check model performance:\n",
    "\n",
    "print('train mse: {}'.format(mean_squared_error(y_train, X_train_preds)))\n",
    "print('train rmse: {}'.format(sqrt(mean_squared_error(y_train, X_train_preds))))\n",
    "print('train r2: {}'.format(r2_score(y_train, X_train_preds)))\n",
    "print()\n",
    "print('test mse: {}'.format(mean_squared_error(y_test, X_test_preds)))\n",
    "print('test rmse: {}'.format(sqrt(mean_squared_error(y_test, X_test_preds))))\n",
    "print('test r2: {}'.format(r2_score(y_test, X_test_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot predictions vs real value\n",
    "\n",
    "plt.scatter(y_test,X_test_preds)\n",
    "plt.xlabel('True Price')\n",
    "plt.ylabel('Predicted Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's explore the importance of the features\n",
    "# the importance is given by the absolute value of the coefficient\n",
    "# assigned by the Lasso\n",
    "\n",
    "importance = pd.Series(np.abs(house_pipe.named_steps['lasso'].coef_))\n",
    "importance.index = list(final_columns)+['LotFrontage_na', 'MasVnrArea_na',  'GarageYrBlt_na']\n",
    "importance.sort_values(inplace=True, ascending=False)\n",
    "importance.plot.bar(figsize=(18,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fengine",
   "language": "python",
   "name": "fengine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "583px",
    "left": "0px",
    "right": "1324px",
    "top": "107px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
